import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Load the dataset
df = pd.read_csv('car_data.csv')

# Data Preprocessing
# Convert categorical variables to numerical using LabelEncoder
le_fuel = LabelEncoder()
le_selling_type = LabelEncoder()
le_transmission = LabelEncoder()

df['Fuel_Type'] = le_fuel.fit_transform(df['Fuel_Type'])
df['Selling_type'] = le_selling_type.fit_transform(df['Selling_type'])
df['Transmission'] = le_transmission.fit_transform(df['Transmission'])

# Calculate car age from Year
current_year = 2025  # Based on current date
df['Car_Age'] = current_year - df['Year']

# Select features and target
features = ['Car_Age', 'Present_Price', 'Driven_kms', 'Fuel_Type', 
           'Selling_type', 'Transmission', 'Owner']
X = df[features]
y = df['Selling_Price']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse:.2f}')
print(f'R2 Score: {r2:.2f}')

# Feature importance
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nFeature Importance:")
print(feature_importance)

# Example prediction
example = X_test.iloc[0].values.reshape(1, -1)
predicted_price = rf_model.predict(example)[0]
print(f"\nExample Prediction: ${predicted_price:.2f} (Actual: ${y_test.iloc[0]:.2f})")
